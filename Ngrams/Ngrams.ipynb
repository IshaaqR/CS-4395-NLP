{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# How to read files from Google Drive: https://colab.research.google.com/notebooks/io.ipynb#scrollTo=RWSJpsyKqHjH\n","from google.colab import drive\n","drive.mount('/content/drive')\n","from nltk import word_tokenize\n","from nltk.util import ngrams\n","import nltk\n","nltk.download('punkt')\n","import pickle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7euzpbSl9Us","executionInfo":{"status":"ok","timestamp":1664685247464,"user_tz":300,"elapsed":21434,"user":{"displayName":"Savishwa","userId":"16686082317361145292"}},"outputId":"2ec941cf-269b-46eb-d621-24e9874f69cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"markdown","source":["# Program 1"],"metadata":{"id":"mC6joi-_60YR"}},{"cell_type":"code","source":["def unigram_bigram(filename):\n","  with open(filename, 'r') as f:\n","    raw_text = f.read()\n","\n","  tokens = word_tokenize(raw_text)\n","  bigrams = list(ngrams(tokens, 2))\n","  unigrams = list(ngrams(tokens, 1))\n","  bigram_dict = {b:bigrams.count(b) for b in set(bigrams)}\n","  unigram_dict = {t:unigrams.count(t) for t in set(unigrams)}\n","\n","  return unigram_dict, bigram_dict"],"metadata":{"id":"DgNWOocjrWRW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["english = '/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/ngram_files/LangId.train.English'\n","french = '/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/ngram_files/LangId.train.French'\n","italian = '/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/ngram_files/LangId.train.Italian'\n","\n","english_unigram, english_bigram = unigram_bigram(english)\n","french_unigram, french_bigram = unigram_bigram(french)\n","italian_unigram, italian_bigram = unigram_bigram(italian)"],"metadata":{"id":"bAZRnp_MuysS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/pickle_files/english_unigram.pickle', 'wb') as handle:\n","    pickle.dump(english_unigram, handle)\n","with open('/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/pickle_files/english_bigram.pickle', 'wb') as handle:\n","    pickle.dump(english_bigram, handle)\n","with open('/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/pickle_files/french_unigram.pickle', 'wb') as handle:\n","    pickle.dump(french_unigram, handle)\n","with open('/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/pickle_files/french_bigram.pickle', 'wb') as handle:\n","    pickle.dump(french_bigram, handle)\n","with open('/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/pickle_files/italian_unigram.pickle', 'wb') as handle:\n","    pickle.dump(italian_unigram, handle)\n","with open('/content/drive/My Drive/Schoolwork/CS 4395/Ngrams/pickle_files/italian_bigram.pickle', 'wb') as handle:\n","    pickle.dump(italian_bigram, handle)"],"metadata":{"id":"p47hTIAljc2K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Program 2"],"metadata":{"id":"gWcztxSO8-aG"}},{"cell_type":"code","source":["eng_uni_dict = pickle.load(open('/content/drive/MyDrive/Ngrams/pickle_files/english_unigram.pickle', 'rb'))\n","eng_bi_dict = pickle.load(open('/content/drive/MyDrive/Ngrams/pickle_files/english_bigram.pickle', 'rb'))\n","fr_uni_dict = pickle.load(open('/content/drive/MyDrive/Ngrams/pickle_files/french_unigram.pickle', 'rb'))\n","fr_bi_dict = pickle.load(open('/content/drive/MyDrive/Ngrams/pickle_files/french_bigram.pickle', 'rb'))\n","ital_uni_dict = pickle.load(open('/content/drive/MyDrive/Ngrams/pickle_files/italian_unigram.pickle', 'rb'))\n","ital_bi_dict = pickle.load(open('/content/drive/MyDrive/Ngrams/pickle_files/italian_bigram.pickle', 'rb'))"],"metadata":{"id":"p-WwWQtp894N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# p = (b + 1) / (u + v)\n","def compute_prob (text, unigram_dict, bigram_dict, V):\n","    p_laplace = 1\n","\n","    unigrams_test = word_tokenize(text)\n","    bigrams_test = list(ngrams(unigrams_test, 2))\n","\n","    for bigram in bigrams_test:\n","        b = bigram_dict[bigram] if bigram in bigram_dict else 0\n","        u = unigram_dict[(bigram[0], )] if (bigram[0], ) in unigram_dict else 0\n","\n","        p_laplace = p_laplace * ((b + 1) / (u + V))\n","    \n","    # print(\"probability with laplace smoothing is %.5f\" % p_laplace)\n","    return p_laplace"],"metadata":{"id":"RVdXMFwIB7LS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["V = len(eng_uni_dict) + len(fr_uni_dict) + len(ital_uni_dict) \n","classifications = {}\n","\n","with open('/content/drive/MyDrive/Ngrams/ngram_files/LangId.test', 'rb') as handle:\n","    lines = handle.readlines()\n","    line_num = 1\n","    for line in lines:\n","        probs = {}\n","        \n","        line = line.decode('utf-8')\n","        p_eng = compute_prob(text = line, unigram_dict = eng_uni_dict, bigram_dict = eng_bi_dict, V = V)\n","        p_fr = compute_prob(text = line, unigram_dict = fr_uni_dict, bigram_dict = fr_bi_dict, V = V)\n","        p_ital = compute_prob(text = line, unigram_dict = ital_uni_dict, bigram_dict = ital_bi_dict, V = V)\n","\n","        probs['English'] = p_eng\n","        probs['French'] = p_fr\n","        probs['Italian'] = p_ital\n","\n","        classifications[line_num] = max(probs, key = probs.get)\n","\n","        line_num += 1\n","\n"],"metadata":{"id":"5yyp2dDh-JEz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open('/content/drive/MyDrive/Ngrams/ngram_files/classifications.txt', 'w') as f:\n","    for key, value in classifications.items():\n","        f.write('%s %s\\n' % (key, value))"],"metadata":{"id":"I7cVAq4WE6Jp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["correct_classifications = {}\n","with open('/content/drive/MyDrive/Ngrams/ngram_files/LangId.sol', 'r') as f:\n","    for line in f.readlines():\n","        line_num, lang = line.split()\n","        correct_classifications[line_num] = lang"],"metadata":{"id":"xjevTZrWKOyS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_correct = 0\n","incorrect_classified = []\n","for key, value in classifications.items():\n","    if classifications[key] == correct_classifications[str(key)]:\n","        num_correct += 1\n","    else:\n","        incorrect_classified.append(key)\n","\n","accuracy = (num_correct / len(classifications)) * 100\n","print('Accuracy: ', accuracy)\n","print('Incorrectly classified: ', incorrect_classified)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vH5Fpq0mLGOg","executionInfo":{"status":"ok","timestamp":1664689140555,"user_tz":300,"elapsed":536,"user":{"displayName":"Savishwa","userId":"16686082317361145292"}},"outputId":"080b9140-ec11-4798-9468-6c0eb1fe47b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy:  97.33333333333334\n","Incorrectly classified:  [24, 44, 92, 187, 191, 247, 277, 279]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HWmb_gvXMyxy"},"execution_count":null,"outputs":[]}]}